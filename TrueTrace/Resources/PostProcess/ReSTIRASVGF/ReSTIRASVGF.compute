#include "../../GlobalDefines.cginc"
#include "../DenoisersCommon.cginc"
#include "UnityCG.cginc"
#pragma warning( disable : 3556)

float ResRatio;

inline float4x4 inverse(float4x4 m) {
    float n11 = m[0][0], n12 = m[1][0], n13 = m[2][0], n14 = m[3][0];
    float n21 = m[0][1], n22 = m[1][1], n23 = m[2][1], n24 = m[3][1];
    float n31 = m[0][2], n32 = m[1][2], n33 = m[2][2], n34 = m[3][2];
    float n41 = m[0][3], n42 = m[1][3], n43 = m[2][3], n44 = m[3][3];

    float t11 = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44;
    float t12 = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44;
    float t13 = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44;
    float t14 = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;

    float det = n11 * t11 + n21 * t12 + n31 * t13 + n41 * t14;
    float idet = 1.0f / det;

    float4x4 ret;

    ret[0][0] = t11 * idet;
    ret[0][1] = (n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44) * idet;
    ret[0][2] = (n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44) * idet;
    ret[0][3] = (n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43) * idet;

    ret[1][0] = t12 * idet;
    ret[1][1] = (n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44) * idet;
    ret[1][2] = (n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44) * idet;
    ret[1][3] = (n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43) * idet;

    ret[2][0] = t13 * idet;
    ret[2][1] = (n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44) * idet;
    ret[2][2] = (n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44) * idet;
    ret[2][3] = (n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43) * idet;

    ret[3][0] = t14 * idet;
    ret[3][1] = (n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34) * idet;
    ret[3][2] = (n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34) * idet;
    ret[3][3] = (n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33) * idet;

    return ret;
}

#ifdef HDRP
    Texture2DArray<float> Depth;
    Texture2DArray<half4> NormalTex;
    Texture2DArray<float2> TEX_PT_MOTION;
#else
    Texture2D<float2> TEX_PT_MOTION;
    Texture2D<half4> NormalTex;
    Texture2D<float> Depth;
#endif

Texture2D<float4> TEX_PT_COLOR_LF_SH;
Texture2D<float2> TEX_PT_COLOR_LF_COCG;
RWTexture2D<float4> TEX_PT_COLOR_LF_SHWrite;
RWTexture2D<half4> TEX_PT_COLOR_HFWrite;
RWTexture2D<uint> TEX_PT_COLOR_SPECWrite;
Texture2D<uint> TEX_PT_COLOR_SPEC;
Texture2D<float4> TEX_ASVGF_HIST_COLOR_LF_SH_B;
RWTexture2D<half2> IMG_ASVGF_GRAD_LF_PING;
RWTexture2D<half2> IMG_ASVGF_GRAD_LF_PONG;
RWTexture2D<half2> IMG_ASVGF_GRAD_HF_SPEC_PING;
RWTexture2D<half2> IMG_ASVGF_GRAD_HF_SPEC_PONG;
Texture2D<half2> TEX_PT_VIEW_DEPTH_A;//current frame depth
Texture2D<half2> TEX_PT_VIEW_DEPTH_B;//previous frame depth

Texture2D<float2> TEX_ASVGF_HIST_COLOR_LF_COCG_B;
Texture2D<half4> TEX_ASVGF_HIST_COLOR_HF;
Texture2D<float2> TEX_ASVGF_FILTERED_SPEC_B;
Texture2D<half4> TEX_ASVGF_HIST_MOMENTS_HF_B;
RWTexture2D<float2> TEX_PT_COLOR_LF_COCGWrite;
RWTexture2D<half4> IMG_ASVGF_HIST_MOMENTS_HF_A;
RWTexture2D<float4> IMG_ASVGF_HIST_COLOR_LF_SH_A;
RWTexture2D<float2> IMG_ASVGF_HIST_COLOR_LF_COCG_A;
RWTexture2D<half4> IMG_ASVGF_ATROUS_PING_HF;
RWTexture2D<uint> IMG_ASVGF_ATROUS_PING_SPEC;
RWTexture2D<float2> IMG_ASVGF_ATROUS_PING_SPEC2;
RWTexture2D<half2> IMG_ASVGF_ATROUS_PING_MOMENTS;
RWTexture2D<float4> IMG_ASVGF_ATROUS_PING_LF_SH;
RWTexture2D<float2> IMG_ASVGF_ATROUS_PING_LF_COCG;

RWTexture2D<half2> MetallicAWrite;
Texture2D<half2> MetallicA;
Texture2D<half2> MetallicB;

Texture2D<half4> TEX_ASVGF_HIST_MOMENTS_HF_A;


RWTexture2D<uint2> TEX_PT_NORMALS_AWrite;
Texture2D<uint2> TEX_PT_NORMALS_A;
Texture2D<uint2> TEX_PT_NORMALS_B;

Texture2D<float4> TEX_ASVGF_HIST_COLOR_LF_SH_A;

Texture2D<float2> TEX_ASVGF_HIST_COLOR_LF_COCG_A;

RWTexture2D<uint> ReflectedRefractedTexWrite;
Texture2D<uint> ReflectedRefractedTex;
Texture2D<uint> ReflectedRefractedTexPrev;

Texture2D<half4> TEX_ASVGF_ATROUS_PING_HF;
SamplerState my_point_clamp_sampler;

StructuredBuffer<float> ExposureBuffer;
bool UseExposure;
float IndirectBoost;

static const int GRAD_DWN = 3;
#define STRATUM_OFFSET_SHIFT 3
#define STRATUM_OFFSET_MASK ((1 << STRATUM_OFFSET_SHIFT) - 1)

static const float gaussian_kernel[2][2] = {
    { 1.0 / 4.0, 1.0 / 8.0  },
    { 1.0 / 8.0, 1.0 / 16.0 }
};

static const float wavelet_factor = 0.5;
static const float wavelet_kernel[2][2] = {
    { 1.0, wavelet_factor  },
    { wavelet_factor, wavelet_factor * wavelet_factor }
};


#pragma kernel CopyData




struct SH {
    float4 shY;
    float2 CoCg;
};

inline SH init_SH()
{
    SH result;
    result.shY = 0;
    result.CoCg = 0;
    return result;
}

inline void accumulate_SH(inout SH accum, SH b, float scale)
{
    accum.shY += b.shY * scale;
    accum.CoCg += b.CoCg * scale;
}

inline SH mix_SH(SH a, SH b, float s)
{
    SH result;
    result.shY = lerp(a.shY, b.shY, s);
    result.CoCg = lerp(a.CoCg, b.CoCg, s);
    return result;
}

inline SH load_SH(Texture2D<float4> img_shY, Texture2D<float2> img_CoCg, int2 p)
{
    SH result;
    result.shY = img_shY[p];
    result.CoCg = img_CoCg[p];
    return result;
}

inline SH load_SH(RWTexture2D<float4> img_shY, RWTexture2D<float2> img_CoCg, int2 p)
{
    SH result;
    result.shY = img_shY[p];
    result.CoCg = img_CoCg[p];
    return result;
}

// Use a macro to work around the glslangValidator errors about function argument type mismatch
#define STORE_SH(img_shY, img_CoCg, p, sh) {img_shY[p] = sh.shY; img_CoCg[p] = sh.CoCg; }

inline void store_SH(RWTexture2D<float4> img_shY, RWTexture2D<float2> img_CoCg, int2 p, SH sh)
{
    img_shY[p] = sh.shY;
    img_CoCg[p] = sh.CoCg;
}

Texture2D<int> Normal;

float FarPlane;

int CurFrame;

SamplerState sampler_trilinear_clamp;


Texture2D<uint4> PrimaryTriData;
Texture2D<uint4> SecondaryTriData;

inline SH irradiance_to_SH(float3 color, float3 dir)
{
    SH result;
    color = log(color + 1);
    float   Co = color.r - color.b;
    float   t = color.b + Co * 0.5;
    float   Cg = color.g - t;
    float   Y = max(t + Cg * 0.5, 0.0);

    result.CoCg = float2(Co, Cg);

    float   L00 = 0.282095;
    float   L1_1 = 0.488603 * dir.y;
    float   L10 = 0.488603 * dir.z;
    float   L11 = 0.488603 * dir.x;

    result.shY = float4 (L11, L1_1, L10, L00) * Y;

    return result;
}

RWTexture2D<uint2> AlbedoColorA;
Texture2D<uint2> AlbedoColorB;



float3 CalcPos(uint4 TriData) {
    if(TriData.w == 99993) return asfloat(TriData.xyz);
    MyMeshDataCompacted Mesh = _MeshData[TriData.x];
    TriData.y += Mesh.TriOffset;
    float4x4 Inverse = inverse(Mesh.W2L);
    return mul(Inverse, float4(AggTrisA[TriData.y].pos0 + asfloat(TriData.z) * AggTrisA[TriData.y].posedge1 + asfloat(TriData.w) * AggTrisA[TriData.y].posedge2,1)).xyz;
}


float3 CalcPos2(uint4 TriData) {
    if(TriData.w == 99993) return asfloat(TriData.xyz);
    MyMeshDataCompacted Mesh = _MeshData[TriData.x];
    TriData.y += Mesh.TriOffset;
    float4x4 Inverse = inverse(Mesh.W2L);
    return mul(Inverse, float4(AggTrisA[TriData.y].pos0 + asfloat(TriData.z) * AggTrisA[TriData.y].posedge1 + asfloat(TriData.w) * AggTrisA[TriData.y].posedge2,1)).xyz;
}

int CalcMat(uint4 TriData) {
    if(TriData.w == 99993) return -1;
    MyMeshDataCompacted Mesh = _MeshData[TriData.x];
    TriData.y += Mesh.TriOffset;
    return AggTrisA[TriData.y].MatDat + Mesh.MaterialOffset;
}


float4x4 viewprojection;
float4x4 prevviewprojection;
int PartialRenderingFactor;
[numthreads(16, 16, 1)]
void CopyData(int3 id : SV_DispatchThreadID)
{
    if(id.x > screen_width || id.y > screen_height) return;
    const int pixel_index = id.y * screen_width + id.x;
    ColData Pixel = GlobalColorsRead[pixel_index];
    Pixel.Flags = packRGBE(max(unpackRGBE(Pixel.Flags), 0.01f));
    float3 TexInverted = max(Pixel.Data, 0.01f);
    float3 TexBaseColor = clamp(TexInverted.xyz,0,12.0f);
    TexBaseColor = (TexBaseColor > 0.005f ? rcp(TexBaseColor) : 0);
    float2 MetRough = FromColorSpecPacked(Pixel.MetRoughIsSpec);
    MetallicAWrite[id.xy] = MetRough;
    #ifdef HDRP
        float2 motion = -TEX_PT_MOTION.SampleLevel(my_linear_clamp_sampler, int3(id.xy,0) / float3(screen_width, screen_height, 1), 0).xy;
    #else
        float2 motion = -TEX_PT_MOTION.SampleLevel(my_linear_clamp_sampler, id.xy / float2(screen_width, screen_height), 0).xy;
    #endif
    
    int2 pos_prev = floor((((float2(id.xy)+0.5f) * float2(rcp(screen_width), rcp(screen_height)) + motion) * float2(screen_width, screen_height)));
    if(any(pos_prev > float2(screen_width, screen_height) || pos_prev < 0)) pos_prev.x = -1000;
    if(((asuint(ScreenSpaceInfo[id.xy].w) << 4) >> 4) != ((asuint(ScreenSpaceInfoPrev[pos_prev].w) << 4) >> 4)) {
        pos_prev.x = -1000;
    }
    if(GetBounceData(Pixel.MetRoughIsSpec) == 1) {
        Pixel.Direct = float3(0,0,0);
        Pixel.Indirect = float3(0,0,0);
        Pixel.PrimaryNEERay = 0;
    }

    bool ReflectedRefracted = max(FromColorSpecPacked(Pixel.MetRoughIsSpec).z - 2,0);
    float3 WorldAlbedo = clamp(unpackRGBE(Pixel.Flags),0,12.0f);
    TexInverted.xyz *= ((WorldAlbedo > 0.001f) ? rcp(WorldAlbedo) : 1.0f);
    float Exposure = 1;
    if(UseExposure) Exposure = ExposureBuffer[0];


    uint2 AlbedoData = Pixel.Flags;
    SH IndirectSH = init_SH();
    float4 HFCol = 0;
    uint SpecCol = 0;
    float3 Direct = Pixel.Direct + pow(unpackRGBE(Pixel.PrimaryNEERay),2.2f) * TexBaseColor;

    const float dielectric_specular = 0.04;
    float3 o_albedo = lerp(unpackRGBE(AlbedoData.x) * (1.0 - dielectric_specular), 0, FromColorSpecPacked(Pixel.MetRoughIsSpec).x * (MetRough.y < 0.6f));
    float3 o_base_reflectivity = lerp(dielectric_specular, unpackRGBE(AlbedoData.x), FromColorSpecPacked(Pixel.MetRoughIsSpec).x * (MetRough.y < 0.6f));
        if(GetBounceData(Pixel.MetRoughIsSpec) != 1) {
            AlbedoData.x = packRGBE(o_albedo);
            AlbedoData.y = packRGBE(o_base_reflectivity);
        }
    [branch]if (!((asuint(ScreenSpaceInfo[id.xy].w) >> 31) & 0x1) && (FromColorSpecPacked(Pixel.MetRoughIsSpec).z == 2 || MetRough.y >= 0.6f)) {
        // if(pos_prev.x != -1000) AlbedoData.y = AlbedoColorB[pos_prev].y;
        IndirectSH = irradiance_to_SH(clamp(PartialRenderingFactor * Exposure * IndirectBoost * clamp(Pixel.Indirect * Pixel.Data.xyz / max(0.01f, o_albedo) / 1024.0f,0,120000),0,120000.0f), clamp(normalize(CalcPos2(SecondaryTriData[id.xy]) - CalcPos(PrimaryTriData[id.xy])),-1,1));
        HFCol = clamp(float4(PartialRenderingFactor * Exposure * (Direct * Pixel.Data.xyz / max(0.01f, o_albedo)),1),0,120000.0f);
    } else {
        // if(pos_prev.x != -1000) AlbedoData.x = AlbedoColorB[pos_prev].x;
        SpecCol = packRGBE(PartialRenderingFactor * max(Exposure * (Direct + IndirectBoost * Pixel.Indirect) * Pixel.Data.xyz / max(0.01f, o_base_reflectivity),0));
    }
    ReflectedRefractedTexWrite[id.xy] = (ReflectedRefracted << 31) | ((asuint(ScreenSpaceInfo[id.xy].w) << 4) >> 4);


    AlbedoColorA[id.xy] = AlbedoData;
    STORE_SH(TEX_PT_COLOR_LF_SHWrite, TEX_PT_COLOR_LF_COCGWrite, id.xy, IndirectSH);
    TEX_PT_COLOR_HFWrite[id.xy] = HFCol;
    TEX_PT_COLOR_SPECWrite[id.xy] = SpecCol;
    if(!ReflectedRefracted) {
        // if((asuint(ScreenSpaceInfo[id.xy].w) >> 31) & 0x1) TEX_PT_NORMALS_AWrite[id.xy] = uint2(octahedral_32(-i_octahedral_32(asuint(Pixel.throughput.x))), octahedral_32(-i_octahedral_32(asuint(Pixel.throughput.y))));
        TEX_PT_NORMALS_AWrite[id.xy] = uint2(asuint(ScreenSpaceInfo[id.xy].xy));//GeoNorm, Norm
    } else {
        TEX_PT_NORMALS_AWrite[id.xy] = TEX_PT_NORMALS_B[pos_prev];
    }

}


uint hash_with(uint seed, uint hash) {
    // Wang hash
    seed = (seed ^ 61) ^ hash;
    seed += seed << 3;
    seed ^= seed >> 4;
    seed *= 0x27d4eb2d;
    return seed;
}
uint pcg_hash(uint seed) {
    uint state = seed * 747796405u + 2891336453u;
    uint word = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;
    return (word >> 22u) ^ word;
}

float2 random(uint samdim, int2 id) {
    uint hash = pcg_hash(((id.x + id.y * screen_width) * (uint)112 + samdim));

    const static float one_over_max_unsigned = asfloat(0x2f7fffff);


    float x = hash_with(CurFrame, hash) * one_over_max_unsigned;
    float y = hash_with(CurFrame + 0xdeadbeef, hash) * one_over_max_unsigned;

    return float2(x, y);

}

int iter;
float CameraDist;
float3 Forward;


#pragma kernel Gradient_Img


inline float get_gradient(float l_curr, float l_prev)
{
    float l_max = max(l_curr, l_prev);

    if (l_max == 0)
        return 0;

    float ret = abs(l_curr - l_prev) / l_max;
    // ret = min(ret, 0.4f);
    ret *= ret; // make small changes less significant

    return ret;
}

inline float2 get_lf_gradient(int2 ipos)
{
    // Find the same surface on the pvreious frame
    #ifdef HDRP
        float2 motion = -TEX_PT_MOTION.SampleLevel(my_linear_clamp_sampler, int3(ipos,0) / float3(screen_width, screen_height, 1), 0).xy;
    #else
        float2 motion = -TEX_PT_MOTION.SampleLevel(my_linear_clamp_sampler, ipos / float2(screen_width, screen_height), 0).xy;
    #endif

    int2 pos_prev = int2(floor(((float2(ipos)+0.5) * float2((rcp(screen_width)), rcp(screen_height)) + motion.xy) * float2(screen_width, screen_height)));

    // Ignore if the surface was outside of the screen
    if (pos_prev.x < 0 || pos_prev.x >= screen_width || pos_prev.y < 0 || pos_prev.y >= screen_height)
        return 0;

    // Get the current path tracer output and the temporally accumulated history.
    // Ignore disocclusion, doesn't seem to be necessary here as there is a huge blur pass
    // done on the LF gradient samples after.
    float lum_curr = TEX_PT_COLOR_LF_SH[ipos].w;
    float lum_prev = TEX_ASVGF_HIST_COLOR_LF_SH_B[pos_prev].w;

    // Return raw colors, do not divide until after the blur pass. We want to detect 
    // brightness changes over large parts of the screen to avoid noise.
    return float2(lum_curr, lum_prev);
}
[numthreads(16, 16, 1)]
void Gradient_Img(uint3 gl_GlobalInvocationID : SV_DispatchThreadID)
{
    int2 ipos = gl_GlobalInvocationID.xy;
    if (any((ipos >= int2(screen_width, screen_height) / GRAD_DWN)))
        return;

    float2 grad_lf = 0;

    // Process all LF samples in the 3x3 square, accumulate the luminances

    for (int yy = 0; yy < GRAD_DWN; yy++)
    {
        for (int xx = 0; xx < GRAD_DWN; xx++)
        {
            grad_lf += get_lf_gradient(ipos * GRAD_DWN + int2(xx, yy));
        }
    }

    IMG_ASVGF_GRAD_LF_PING[ipos] = grad_lf;
}




Texture2D<half2> TEX_ASVGF_GRAD_LF_PONG;
Texture2D<half2> TEX_ASVGF_GRAD_LF_PING;
Texture2D<half2> TEX_ASVGF_GRAD_HF_SPEC_PING;
Texture2D<half2> TEX_ASVGF_GRAD_HF_SPEC_PONG;


#pragma kernel Gradient_Atrous

int iteration;

inline float2 filter_image(Texture2D<half2> img, int2 ipos)
{
    int2 grad_size = int2(screen_width, screen_height) / GRAD_DWN;

    float2 color_center = img[ipos].xy;

    float sum_w = 1;

    const int step_size = int(1u << iteration);

    float2 sum_color = 0;
    sum_w = 0;
    ipos += (random(64, ipos) - 0.5f);

    const int r = 1;
    for (int yy = -r; yy <= r; yy++) {
        for (int xx = -r; xx <= r; xx++) {
            int2 p = ipos + int2(xx, yy) * step_size;

            float2  c = img[p].xy;

            if (any((p >= grad_size) || p < 0))
                c = 0;

            float w = wavelet_kernel[abs(xx)][abs(yy)];// / (float)step_size;

            sum_color += c * w;
            sum_w += w;
        }
    }
    sum_color /= sum_w;


    return sum_color;
}

[numthreads(16, 16, 1)]
void Gradient_Atrous(uint3 id : SV_DispatchThreadID)
{

    int2 ipos = id.xy;
    int2 grad_size = int2(screen_width, screen_height) / GRAD_DWN;
    if (any((ipos >= grad_size) || ipos < 0))
        return;

    float2 filtered_lf = 0;
    float2 filtered_hf_spec = 0;
    [branch] switch (iteration) {
    case 0: filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PING, id.xy); filtered_hf_spec = filter_image(TEX_ASVGF_GRAD_HF_SPEC_PING, id.xy); break;
    case 1: filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PONG, id.xy); filtered_hf_spec = filter_image(TEX_ASVGF_GRAD_HF_SPEC_PONG, id.xy); break;
    case 2: filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PING, id.xy); filtered_hf_spec = filter_image(TEX_ASVGF_GRAD_HF_SPEC_PING, id.xy); break;
    case 3: filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PONG, id.xy); break;
    case 4: filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PING, id.xy); break;
    case 5: filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PONG, id.xy); break;
    case 6:
        filtered_lf = filter_image(TEX_ASVGF_GRAD_LF_PING, id.xy);
        filtered_lf.x = get_gradient((exp(filtered_lf.x) - 1) * 1024.0f * 1024.0f, (exp(filtered_lf.y) - 1) * 1024.0f * 1024.0f);
        filtered_lf.y = 0;
        break;
    }

    [branch] switch (iteration) {
    case 0: IMG_ASVGF_GRAD_LF_PONG[ipos] = filtered_lf; IMG_ASVGF_GRAD_HF_SPEC_PONG[ipos] = filtered_hf_spec; break;
    case 1: IMG_ASVGF_GRAD_LF_PING[ipos] = filtered_lf; IMG_ASVGF_GRAD_HF_SPEC_PING[ipos] = filtered_hf_spec; break;
    case 2: IMG_ASVGF_GRAD_LF_PONG[ipos] = filtered_lf; IMG_ASVGF_GRAD_HF_SPEC_PONG[ipos] = filtered_hf_spec; break;
    case 3: IMG_ASVGF_GRAD_LF_PING[ipos] = filtered_lf; break;
    case 4: IMG_ASVGF_GRAD_LF_PONG[ipos] = filtered_lf; break;
    case 5: IMG_ASVGF_GRAD_LF_PING[ipos] = filtered_lf; break;
    case 6: IMG_ASVGF_GRAD_LF_PONG[ipos] = filtered_lf; break;
    }

}


#define GROUP_SIZE 15
// spatially compute variance in a 3x3 (radius = 1) or a 5x5 (radius = 2) window 
#define FILTER_RADIUS 1 
// size of the shared memory copies of color, depth, and normals
#define SHARED_SIZE (GROUP_SIZE + FILTER_RADIUS * 2)



#pragma kernel Temporal

groupshared float4 s_normal_lum[SHARED_SIZE][SHARED_SIZE];
groupshared float s_depth[SHARED_SIZE][SHARED_SIZE];
groupshared float4 s_lf_shy[GROUP_SIZE][GROUP_SIZE];
groupshared float2 s_lf_cocg[GROUP_SIZE][GROUP_SIZE];





inline void preload(int2 gl_WorkGroupID, int gl_LocalInvocationIndex)
{
    int2 groupBase = gl_WorkGroupID * GROUP_SIZE - FILTER_RADIUS;

    // The size of these shared memory buffers is larger than the group size because we 
    // use them for some spatial filtering. So a single load per thread is not enough.
    // Rename the threads so that some of them will load 2 pixels, and most will load 1 pixel, 
    // in the most dense way possible.
    for (uint linear_idx = gl_LocalInvocationIndex; linear_idx < SHARED_SIZE * SHARED_SIZE; linear_idx += GROUP_SIZE * GROUP_SIZE)
    {
        // Convert the linear index to 2D index in a SHARED_SIZE x SHARED_SIZE virtual group
        float t = (float(linear_idx) + 0.5) / float(SHARED_SIZE);
        int xx = int(floor(frac(t) * float(SHARED_SIZE)));
        int yy = int(floor(t));

        // Load
        int2 ipos = groupBase + int2(xx, yy);
        float depth = TEX_PT_VIEW_DEPTH_A[ipos].x;
        float3 normal = i_octahedral_32(TEX_PT_NORMALS_A[ipos].y);
        float3 color_hf = IMG_ASVGF_ATROUS_PING_HF[ipos];

        // Store
        s_normal_lum[yy][xx] = float4(normal.xyz, luminance(color_hf.rgb));//packHalf4x16(float4(normal.xyz, luminance(color_hf.rgb)));
        s_depth[yy][xx] = depth;
    }
}


inline void get_shared_data(int2 offset, out float depth, out float3 normal, out float lum_hf, int2 gl_LocalInvocationID)
{
    int2 addr = gl_LocalInvocationID + int2(FILTER_RADIUS, FILTER_RADIUS) + offset;

    float4 normal_lum = s_normal_lum[addr.y][addr.x];
    depth = s_depth[addr.y][addr.x];

    normal = normal_lum.xyz;
    lum_hf = normal_lum.w;
}

Texture2D<float4> TEX_ASVGF_ATROUS_PONG_LF_SH;
Texture2D<float2> TEX_ASVGF_ATROUS_PONG_LF_COCG;
float3 CamDelta;

[numthreads(GROUP_SIZE, GROUP_SIZE, 1)]
void Temporal(uint3 gl_GlobalInvocationID : SV_DispatchThreadID, uint3 gl_WorkGroupID : SV_GroupID, uint gl_LocalInvocationIndex : SV_GroupIndex, uint3 gl_LocalInvocationID : SV_GroupThreadID)
{
    preload(gl_WorkGroupID, gl_LocalInvocationIndex);
    GroupMemoryBarrierWithGroupSync();

    int2 ipos = gl_GlobalInvocationID.xy;
    #ifdef HDRP
        float2 motion = -TEX_PT_MOTION.SampleLevel(my_linear_clamp_sampler, int3(ipos,0) / float3(screen_width, screen_height, 1), 0).xy;
    #else
        float2 motion = -TEX_PT_MOTION.SampleLevel(my_linear_clamp_sampler, ipos / float2(screen_width, screen_height), 0).xy;
    #endif


    float2 pos_prev = ((((float2(ipos)+0.5f) * float2(rcp(screen_width), rcp(screen_height)) + motion.xy) * float2(screen_width, screen_height)));// + (random(54, gl_GlobalInvocationID) - 0.5f) * 0.2f;

    // Load the parameters of the target pixel
    float depth_curr;
    float3 normal_curr;
    float lum_curr_hf;
    get_shared_data(0, depth_curr, normal_curr, lum_curr_hf, gl_LocalInvocationID);
    Ray ray = CreateCameraRay(ipos / float2(screen_width, screen_height) * 2.0f - 1.0f);
    float4 curprojectedrefl = mul(viewprojection, float4(ray.origin + ray.direction * depth_curr, 1));
    float4 prevprojectedrefl = mul(prevviewprojection, float4(ray.origin + ray.direction * depth_curr, 1));
    float2 reflprojection = ((curprojectedrefl.xy / curprojectedrefl.w) - (prevprojectedrefl.xy / prevprojectedrefl.w)) * 0.5f;

    int MatDat = (ReflectedRefractedTex[gl_GlobalInvocationID.xy] << 4) >> 4;
    bool ReflectedRefracted = ReflectedRefractedTex[gl_GlobalInvocationID.xy] >> 31;
    float motion_length = length((motion.xy + reflprojection) * float2(screen_width, screen_height));
    // float motion_length = length((motion.xy) * float2(screen_width, screen_height));

    float CenterFDepth = TEX_PT_VIEW_DEPTH_A[ipos].y;

    float shininess = clamp(2.0 / max(pow(MetallicA[ipos].y, 4), 0.001f) - 2.0, 0.0, 32.0);

    float3 geo_normal_curr = i_octahedral_32(TEX_PT_NORMALS_A[ipos].x);

    // Try to get the history sample for all channels, including HF moments
    bool temporal_sample_valid_diff = false;
    bool temporal_sample_valid_spec = false;
    SH temporal_color_lf = init_SH();
    float3 temporal_color_hf = 0;
    float4 temporal_moments_histlen_hf = 0;
    float4 temporal_color_histlen_spec = 0;
        float temporal_sum_w_diff = 0.0;
        float temporal_sum_w_spec = 0.0;

        float2 pos_ld = floor(pos_prev - 0.5);
        float2 subpix = frac(pos_prev - 0.5 - pos_ld);
    {

        // Bilinear/bilateral filter
        static const int2 off[4] = { { 0, 0 }, { 1, 0 }, { 0, 1 }, { 1, 1 } };
        const float w[4] = {
            (1.0 - subpix.x) * (1.0 - subpix.y),
            (subpix.x) * (1.0 - subpix.y),
            (1.0 - subpix.x) * (subpix.y),
            (subpix.x) * (subpix.y)
        };
        [unroll]for (int i = 0; i < 4; i++) {
            int2 p = int2(pos_ld)+off[i];

            if (p.x < 0 || p.x >= screen_width || p.y >= screen_height)
                continue;

            float depth_prev = TEX_PT_VIEW_DEPTH_B[p].x;
            uint2 norms = TEX_PT_NORMALS_B[p];
            float3  normal_prev = i_octahedral_32(norms.y);
            float3  geo_normal_prev = i_octahedral_32(norms.x);//needs to be TEX_PT_GEO_NORMAL_B, but since for now I am not worrying about normal maps yet, it can use the same texture
            

            float dist_depth = (abs(depth_curr - depth_prev) - CameraDist) / depth_curr * max(CenterFDepth,0.25f);
            float dot_normals = dot(normal_curr, normal_prev);
            float dot_geo_normals = dot(geo_normal_curr, geo_normal_prev);
            if(((ReflectedRefractedTexPrev[p] << 4) >> 4) == MatDat)
            [branch]if(!(ReflectedRefracted) && !(ReflectedRefractedTexPrev[p] >> 31)) {
                if (dist_depth < 0.1 && dot_geo_normals > 0.8)
                {
                    float w_diff = w[i] * max(dot_normals, 0);
                    float w_spec = w[i] * pow(max(dot_normals, 0), shininess);

                        SH hist_color_lf = load_SH(TEX_ASVGF_HIST_COLOR_LF_SH_B, TEX_ASVGF_HIST_COLOR_LF_COCG_B, p);
                        accumulate_SH(temporal_color_lf, hist_color_lf, w_diff);
    

                    temporal_color_hf += TEX_ASVGF_HIST_COLOR_HF[p] * w_diff;
                    temporal_color_histlen_spec += float4(unpackRGBE(asuint(TEX_ASVGF_FILTERED_SPEC_B[p].x)), TEX_ASVGF_FILTERED_SPEC_B[p].y) * w_spec;
                    temporal_moments_histlen_hf += TEX_ASVGF_HIST_MOMENTS_HF_B[p].rgba * w_diff;
                    temporal_sum_w_diff += w_diff;
                    temporal_sum_w_spec += w_spec;
                }
            } else {
                if (dist_depth < 0.1)
                {
                    float w_diff = pow(w[i],clamp(6.0f / depth_curr,1.0f, 3.0f));
                    float w_spec = w[i];

                    SH hist_color_lf = load_SH(TEX_ASVGF_HIST_COLOR_LF_SH_B, TEX_ASVGF_HIST_COLOR_LF_COCG_B, p);
                    accumulate_SH(temporal_color_lf, hist_color_lf, w_diff);

                    temporal_color_hf += TEX_ASVGF_HIST_COLOR_HF[p] * w_diff;
                    temporal_color_histlen_spec += float4(unpackRGBE(asuint(TEX_ASVGF_FILTERED_SPEC_B[p].x)), TEX_ASVGF_FILTERED_SPEC_B[p].y) * w_spec;
                    temporal_moments_histlen_hf += TEX_ASVGF_HIST_MOMENTS_HF_B[p].rgba * w_diff;
                    temporal_sum_w_diff += w_diff;
                    temporal_sum_w_spec += w_spec;
                }   
            }
        }

        // We found some relevant surfaces - good
        if (temporal_sum_w_diff > 1e-6)
        {
            float inv_w_diff = 1.0 / temporal_sum_w_diff;
            temporal_color_lf.shY *= inv_w_diff;
            temporal_color_lf.CoCg *= inv_w_diff;
            temporal_color_hf *= inv_w_diff;
            temporal_moments_histlen_hf *= inv_w_diff;
            temporal_sample_valid_diff = true;
        }

        if (temporal_sum_w_spec > 1e-6)
        {
            float inv_w_spec = 1.0 / temporal_sum_w_spec;
            temporal_color_histlen_spec *= inv_w_spec;
            temporal_sample_valid_spec = true;
        }

    }


    // Compute spatial moments of the HF channel in a 3x3 window
    float2 spatial_moments_hf = float2(lum_curr_hf, lum_curr_hf * lum_curr_hf);

    {
        float spatial_sum_w_hf = 1.0;
        for (int yy = -1; yy <= 1; yy++) {
            for (int xx = -1; xx <= 1; xx++) {
                if (xx == 0 && yy == 0)
                    continue;

                int2 p = ipos + int2(xx, yy);

                float depth;
                float3 normal;
                float lum_p_hf;
                get_shared_data(int2(xx, yy), depth, normal, lum_p_hf, gl_LocalInvocationID);
                // lum_p_hf += luminance(unpackRGBE(TEX_PT_COLOR_SPEC[p].x));
                float dist_z = abs(depth_curr - depth) / abs(depth_curr) * CenterFDepth;// * FDepth[ipos] * 120.0f;
                if (dist_z < 2.0) {
                    float w_hf = clamp(pow(max(0.0, dot(normal, normal_curr)), 128.0),0,1);

                    spatial_moments_hf += float2(lum_p_hf * w_hf, lum_p_hf * lum_p_hf * w_hf);
                    spatial_sum_w_hf += w_hf;
                }
            }
        }

        float inv_w2_hf = 1.0f / spatial_sum_w_hf;
        spatial_moments_hf *= inv_w2_hf;
    }

    // Load the target pixel colors for all channels
    SH color_curr_lf = load_SH(TEX_PT_COLOR_LF_SH, TEX_PT_COLOR_LF_COCG, ipos);
    float3 color_curr_hf = IMG_ASVGF_ATROUS_PING_HF[ipos];
    float3 color_curr_spec = unpackRGBE(TEX_PT_COLOR_SPEC[ipos].x);

    SH out_color_lf;
    float3 out_color_hf;
    float4 out_color_histlen_spec;
    float4 out_moments_histlen_hf;

    // Load the gradients
    float grad_lf = TEX_ASVGF_GRAD_LF_PONG[ipos / GRAD_DWN].r;
    grad_lf = clamp(grad_lf, 0, 1);
    float2 grad_hf_spec = TEX_ASVGF_GRAD_HF_SPEC_PONG[ipos / GRAD_DWN].rg;
    grad_hf_spec = grad_lf;//clamp(grad_hf_spec, 0, 1);

    if (temporal_sample_valid_diff)
    {
        // Compute the antilag factors based on the gradients
        float antilag_alpha_lf = clamp(lerp(1.0, 1.0f * grad_lf, 1.0f), 0, 1);//play with the middle 2 values?
        float antilag_alpha_hf = clamp(lerp(1.0, 1.0f * grad_hf_spec.x, 1.0f), 0, 1);//play with the middle 2 values?

        // Adjust the history length, taking the antilag factors into account
        float hist_len_hf = min(temporal_moments_histlen_hf.b * pow(1.0 - antilag_alpha_hf, 10) + 1.0, 256.0);
        float hist_len_lf = min(temporal_moments_histlen_hf.a * pow(1.0 - antilag_alpha_lf, 10) + 1.0, 256.0);

        // Compute the blending weights based on history length, so that the filter
        // converges faster. I.e. the first frame has weight of 1.0, the second frame 1/2, third 1/3 and so on.
        float alpha_color_lf = max(0.01f, 1.0f / hist_len_lf);
        float alpha_color_hf = max(0.02f, 1.0f / hist_len_hf);
        float alpha_moments_hf = max(0.01f, 1.0f / hist_len_hf);

        // Adjust the blending factors, taking the antilag factors into account again
        alpha_color_lf = lerp(alpha_color_lf, 1.0, antilag_alpha_lf);
        alpha_color_hf = lerp(alpha_color_hf, 1.0, antilag_alpha_hf);
        alpha_moments_hf = lerp(alpha_moments_hf, 1.0, antilag_alpha_hf);

        // Blend!
        out_color_lf = mix_SH(temporal_color_lf, color_curr_lf, alpha_color_lf);
        out_color_hf.rgb = lerp(temporal_color_hf.rgb, color_curr_hf.rgb, alpha_color_hf);

        out_moments_histlen_hf.rg = lerp(temporal_moments_histlen_hf.rg, spatial_moments_hf.rg, alpha_moments_hf);
        out_moments_histlen_hf.b = hist_len_hf;
        out_moments_histlen_hf.a = hist_len_lf;
    }
    else
    {
        // No valid history - just use the current color and spatial moments
        out_color_lf = color_curr_lf;
        out_color_hf.rgb = color_curr_hf;
        out_moments_histlen_hf = float4(spatial_moments_hf, 1, 1);
    }

    if (temporal_sample_valid_spec)
    {
        float3 Max = 0;
        for(int x = -1; x <= 1; x++) {
            for(int y = -1; y <= 1; y++) {
                if(x == 0 && y == 0) continue;
                float3 col = unpackRGBE(TEX_PT_COLOR_SPEC[ipos + int2(x,y)]);
                Max = max(Max, col);
            }
        }
        color_curr_spec.rgb = exp(clamp(log(color_curr_spec.rgb + 1), 0, log(Max + 15))) - 1;

        // Same sequence as above, only for the specular channel
        float antilag = grad_hf_spec.y * clamp(1.0f - motion_length, 0.1f, 1.0f) + motion_length * 0.001f;
        // float antilag = grad_hf_spec.y + motion_length * 0.001f;
        float antilag_alpha_spec = clamp(lerp(0.0, antilag, 1), 0, 1);
        float hist_len_spec = min(temporal_color_histlen_spec.a * pow(1.0 - antilag_alpha_spec, 10) + 1.0, 256.0);
        float alpha_color_spec = max(0.01f, 1.0 / hist_len_spec);
        alpha_color_spec = lerp(alpha_color_spec, 1.0, antilag_alpha_spec);
        out_color_histlen_spec.rgb = lerp(temporal_color_histlen_spec.rgb, color_curr_spec.rgb, alpha_color_spec);
        out_color_histlen_spec.a = hist_len_spec;
    }
    else
    {
        out_color_histlen_spec = float4(color_curr_spec, 1);
    }


    // Store the outputs for furhter processing by the a-trous HF filter
    IMG_ASVGF_HIST_MOMENTS_HF_A[ipos] = out_moments_histlen_hf;
    STORE_SH(IMG_ASVGF_HIST_COLOR_LF_SH_A, IMG_ASVGF_HIST_COLOR_LF_COCG_A, ipos, out_color_lf);
    IMG_ASVGF_ATROUS_PING_HF[ipos] = float4(out_color_hf,1);
    IMG_ASVGF_ATROUS_PING_SPEC2[ipos] = float2(asfloat(packRGBE(out_color_histlen_spec)), out_color_histlen_spec.a);
    IMG_ASVGF_ATROUS_PING_MOMENTS[ipos] = out_moments_histlen_hf.xy;

    // GroupMemoryBarrierWithGroupSync();

    // Store the LF channel into shared memory for averaging
    s_lf_shy[gl_LocalInvocationID.y][gl_LocalInvocationID.x] = out_color_lf.shY;
    s_lf_cocg[gl_LocalInvocationID.y][gl_LocalInvocationID.x] = out_color_lf.CoCg;

    GroupMemoryBarrierWithGroupSync();

    // Comptue a 1/3-resolution version of the LF channel for this group.
    // Use a bilateral filter that takes the center pixel of each 3x3 square as the anchor.

    float2 lowres_local_id;
    lowres_local_id.x = gl_LocalInvocationIndex % (GROUP_SIZE / GRAD_DWN);
    lowres_local_id.y = gl_LocalInvocationIndex / (GROUP_SIZE / GRAD_DWN);

    if (lowres_local_id.y >= (GROUP_SIZE / GRAD_DWN))
        return;

    // Load the anchor pixel info
    float2 center_shared_pos = lowres_local_id * GRAD_DWN + 1;
    float3 center_normal = s_normal_lum[center_shared_pos.y + FILTER_RADIUS][center_shared_pos.x + FILTER_RADIUS].xyz;
    float center_depth = s_depth[center_shared_pos.y + FILTER_RADIUS][center_shared_pos.x + FILTER_RADIUS];
    float depth_width = TEX_PT_VIEW_DEPTH_A[ipos].y;

    SH center_lf;
    center_lf.shY = s_lf_shy[center_shared_pos.y][center_shared_pos.x];
    center_lf.CoCg = s_lf_cocg[center_shared_pos.y][center_shared_pos.x];

    float sum_w = 1;
    SH sum_lf = center_lf;

    // Average the anchor pixel color with the relevant neighborhood
    [unroll]for (int yy = -1; yy <= 1; yy++)
    {
        [unroll]for (int xx = -1; xx <= 1; xx++)
        {
            if (yy == 0 && xx == 0)
                continue;

            // float3 p_normal = s_normal_lum[center_shared_pos.y + FILTER_RADIUS + yy][center_shared_pos.x + FILTER_RADIUS + xx].xyz;
            float p_depth = s_depth[center_shared_pos.y + FILTER_RADIUS + yy][center_shared_pos.x + FILTER_RADIUS + xx];

            float dist_depth = abs(p_depth - center_depth) * depth_width;
            if (dist_depth < 2)
            {
                float w = 1;//pow(max(dot(p_normal, center_normal), 0), 8);

                SH p_lf;
                p_lf.shY = s_lf_shy[center_shared_pos.y + yy][center_shared_pos.x + xx];
                p_lf.CoCg = s_lf_cocg[center_shared_pos.y + yy][center_shared_pos.x + xx];

                accumulate_SH(sum_lf, p_lf, w);
                sum_w += w;
            }
        }
    }

    float inv_w = 1.0f / (sum_w);
    sum_lf.shY *= inv_w;
    sum_lf.CoCg *= inv_w;

    // Store the LF result for further processing by the a-trous LF filter
    int2 ipos_lowres = int2(gl_WorkGroupID.xy) * (GROUP_SIZE / GRAD_DWN) + int2(lowres_local_id);
    STORE_SH(IMG_ASVGF_ATROUS_PING_LF_SH, IMG_ASVGF_ATROUS_PING_LF_COCG, ipos_lowres, sum_lf);
}



#pragma kernel Atrous_LF

int MaxIterations;

uniform bool UseASVGF;
Texture2D<half> LFVarianceA;
RWTexture2D<half> LFVarianceB;

inline float3 project_SH_irradiance(SH sh, float3 N)
{
    float d = dot(sh.shY.xyz, N);
    float Y = 2.0 * (1.023326 * d + 0.886226 * sh.shY.w);
    Y = max(Y, 0.0);

    sh.CoCg *= Y * 0.282095 / (sh.shY.w + 1e-6);

    float   T = Y - sh.CoCg.y * 0.5;
    float   G = sh.CoCg.y + T;
    float   B = T - sh.CoCg.x * 0.5;
    float   R = B + sh.CoCg.x;

    return max(exp(float3(R, G, B)) - 1, 0.0);
}


static const int STEPS[] = {1,2,3,4,2,1};
inline void filter_image(
    Texture2D<float4> img_lf_shY,
    Texture2D<float2> img_lf_CoCg,
    out SH filtered_lf, int2 gl_GlobalInvocationID)
{
    int2 ipos_lowres = gl_GlobalInvocationID;
    int2 ipos_hires = ipos_lowres * GRAD_DWN + 1;

    // Load the color of the target low-res pixel
    SH color_center_lf = load_SH(img_lf_shY, img_lf_CoCg, ipos_lowres);
    int Iter2 = STEPS[iteration - 1];
    const float CenterMetallic = MetallicA[ipos_hires].x;

    float3 geo_normal_center = i_octahedral_32(TEX_PT_NORMALS_A[ipos_hires].x);
    float depth_center = TEX_PT_VIEW_DEPTH_A[ipos_hires];

    float step_size = int(1u << (Iter2));
    // if(ipos_hires.x > screen_width / 2 && iteration > 0) step_size = (1u << (5 - iteration));
    // if(iteration == 4) step_size = int(1u << (1));
    float hist_len_lf = TEX_ASVGF_HIST_MOMENTS_HF_A[ipos_hires].a;
    float sum_w_lf = 1;
    SH sum_color_lf = color_center_lf;

    float TotVariance = LFVarianceA[ipos_lowres];/// (1.0f + (hist_len_lf / 8.0f));
    float Weight1 = max((exp(img_lf_shY[ipos_lowres].w) - 1) * 1024.0f* 1024.0f,0);

    // Compute the weighted average of color and moments from a sparse 3x3 pattern around the target pixel
    const int r = 1;
    for (int yy = -r; yy <= r; yy++) {
        for (int xx = -r; xx <= r; xx++) {
            if (xx == 0 && yy == 0)
                continue;
            int2 p_lowres = ipos_lowres + int2(xx, yy) * step_size;
            int2 p_hires = p_lowres * GRAD_DWN + 1;


            float w = float(all((p_hires >= int2(0, 0)))
                && all((p_hires < int2(screen_width, screen_height))));
            if(w == 0) continue;
            // Use geometric normals here so that we can blur over larger areas.
            // The lighting detail will be partially preserved by spherical harmonics.
            float3 geo_normal = i_octahedral_32(TEX_PT_NORMALS_A[p_hires].x);

            float depth = TEX_PT_VIEW_DEPTH_A[p_hires];

            float dist_z = abs(depth_center.x - depth);// * (depth_center.y + 1.0f);
            w *= exp(-dist_z);
            w *= wavelet_kernel[abs(xx)][abs(yy)];
            // w *= (2.0f - (1 + LFVarianceA[p_lowres]));


            float w_lf = w;

            SH c_lf = load_SH(img_lf_shY, img_lf_CoCg, p_lowres);

            float Weight2 = max((exp(img_lf_shY[p_lowres].w) - 1) * 1024.0f* 1024.0f,0);

            float GNdotGN = max(0.0, dot(geo_normal_center, geo_normal));
            w_lf *= pow(GNdotGN, 8);
            float w_l = clamp(exp(-pow(abs(Weight2 - Weight1) / (1.0f + (Weight1)),1) * max(1.0f - LFVarianceA[p_lowres], 0)  * clamp(pow(hist_len_lf / 32.0f,2), 0, 1)),0.01f, 1.0f);
            if ((Weight1 + Weight2) / 2048.0f > 0.01f && Iter2 >= 1 && Iter2 < 5)
                w_lf *= w_l;
            // if(w_lf < 0.1f) continue;
            float2 MetRough = MetallicA[p_hires];
            w_lf *= 1.0f - clamp(abs(MetRough.x - CenterMetallic), 0, 1);
            // The 4th iteration has filter footprint big enough to step over obstacles and produce noticeable light leaking.
            // Prevent that by throwing away samples that are too bright. This also helps make some shadows a bit sharper.
            if (iteration >= 3 && iteration <= 4)
                w_lf *= clamp(1.5 - Weight2 / Weight1 * 0.25, 0, 1);
            TotVariance += LFVarianceA[p_lowres] * w_lf;
            accumulate_SH(sum_color_lf, c_lf, w_lf);
            sum_w_lf += w_lf;
        }
    }
    filtered_lf.shY = sum_color_lf.shY / sum_w_lf;
    filtered_lf.CoCg = sum_color_lf.CoCg / sum_w_lf;
    LFVarianceB[ipos_lowres] = TotVariance / sum_w_lf;
}

inline void deflicker_image(
    Texture2D<float4> img_lf_shY,
    Texture2D<float2> img_lf_CoCg,
    out SH filtered_lf, int2 gl_GlobalInvocationID)
{
    int2 ipos_lowres = gl_GlobalInvocationID;
    SH color_center_lf = load_SH(img_lf_shY, img_lf_CoCg, ipos_lowres);
    int2 ipos_hires = ipos_lowres * GRAD_DWN + 1;

    SH sum_color_lf = init_SH();

    const int r = 1;
    const float num_pixels = pow(r * 2 + 1, 2) - 1;
    float MaxLum = 0;
    float MinLum = 9999.0f;
    for (int yy = -r; yy <= r; yy++) {
        for (int xx = -r; xx <= r; xx++) {
            if (xx == 0 && yy == 0)
                continue;
            int2 p_lowres = ipos_lowres + int2(xx, yy);


            SH c_lf = load_SH(img_lf_shY, img_lf_CoCg, p_lowres);
            MaxLum = max(MaxLum, c_lf.shY.w);
            MinLum = min(MinLum, c_lf.shY.w);
            accumulate_SH(sum_color_lf, c_lf, 1.0);
        }
    }


    float max_lum = sum_color_lf.shY.w * 2 / num_pixels;
    if (color_center_lf.shY.w > max_lum)
    {
        float ratio = max_lum / color_center_lf.shY.w;
        LFVarianceB[gl_GlobalInvocationID.xy] = ratio;
    } else {
        LFVarianceB[gl_GlobalInvocationID.xy] = 0.1f;
    }

    filtered_lf = color_center_lf;
}

Texture2D<float4> TEX_ASVGF_ATROUS_PING_LF_SH;
Texture2D<float2> TEX_ASVGF_ATROUS_PING_LF_COCG;
RWTexture2D<float4> IMG_ASVGF_ATROUS_PONG_LF_SH;
RWTexture2D<float2> IMG_ASVGF_ATROUS_PONG_LF_COCG;


[numthreads(16, 16, 1)]
void Atrous_LF(uint3 gl_GlobalInvocationID : SV_DispatchThreadID, uint3 gl_WorkGroupID : SV_GroupID, uint gl_LocalInvocationIndex : SV_GroupIndex, uint3 gl_LocalInvocationID : SV_GroupThreadID)
{

    int2 ipos = gl_GlobalInvocationID;
    if (any((ipos * GRAD_DWN >= int2(screen_width, screen_height))))
        return;

    SH filtered_lf;

    if(iteration == 0) deflicker_image(TEX_ASVGF_ATROUS_PING_LF_SH, TEX_ASVGF_ATROUS_PING_LF_COCG, filtered_lf, ipos);
    else filter_image(TEX_ASVGF_ATROUS_PING_LF_SH, TEX_ASVGF_ATROUS_PING_LF_COCG, filtered_lf, ipos);

    STORE_SH(IMG_ASVGF_ATROUS_PONG_LF_SH, IMG_ASVGF_ATROUS_PONG_LF_COCG, ipos, filtered_lf);
}


#pragma kernel Atrous


bool plane_distance_disocclusion_check(float3 current_pos, float3 history_pos, float3 current_normal)
{
    float3  to_current    = current_pos - history_pos;
    float dist_to_plane = abs(dot(to_current, current_normal));

    return dist_to_plane > 0.01f;
}
uniform int spec_iteration;

float square(float x) { return x * x; }

// Converts a square of roughness to a Phong specular power
float RoughnessSquareToSpecPower(in float alpha) {
    return max(0.01, 2.0f / (square(alpha) + 1e-4) - 2.0f);
}

inline void filter_image(
    Texture2D<half4> img_hf,
    Texture2D<uint> img_spec,
    Texture2D<half2> img_moments,
    out float3 filtered_hf,
    out float3 filtered_spec,
    out float2 filtered_moments,
    int2 gl_GlobalInvocationID)
{
    int2 ipos = int2(gl_GlobalInvocationID);

    float3 color_center_hf = img_hf[ipos];
    float3 color_center_spec = unpackRGBE(img_spec[ipos]);
    float2 moments_center = img_moments[ipos].xy;

    filtered_hf = color_center_hf;
    filtered_spec = color_center_spec;
    filtered_moments = moments_center;

    float depth_center = TEX_PT_VIEW_DEPTH_A[ipos].x;
    float fwidth_depth = TEX_PT_VIEW_DEPTH_A[ipos].y;
    Ray CenterRay = CreateCameraRay((float2)ipos / float2(screen_width, screen_height) * 2.0f - 1.0f);
    float3 CenterPos = CenterRay.direction * depth_center + CenterRay.origin;


    float lum_mean_hf = luminance(color_center_hf);
    float sigma_l_hf = 0;

    float hist_len_hf = TEX_ASVGF_HIST_MOMENTS_HF_A[ipos].b;
    float3 normal_center = normalize(i_octahedral_32(TEX_PT_NORMALS_A[ipos].y));
    float step_size = (1u << (spec_iteration));
    if(spec_iteration > 0) step_size = (1u << (5 - spec_iteration));
    if(spec_iteration != 1) {//should be 4?
        float3 Min = 9999.0f;
        float3 Max = -9999.0f;
        int ValidTaps = 0;
        [unroll]for(int i = -1; i <= 1; i++) {
            [unroll]for(int j = -1; j <= 1; j++) {
                int2 offID = ipos + int2(i, j) * step_size;
                if(i == 0 && j == 0) continue;
                float3 Val = unpackRGBE(img_spec[offID]);
                if(luminance(Val) != 0) {
                    ValidTaps++;
                }
                    Min = min(Min, Val);
                    Max = max(Max, Val);
            }
        }
        filtered_spec = clamp(filtered_spec, Min, Max);
    }
    [branch]if (hist_len_hf > 2 || spec_iteration == 0) {
        // Compute luminance variance from the statistical moments: Var(X) = E[X^2] - E[X]^2
        // The `asvgf_temporal` shader computes a combination of temporal and spatial (3x3) moments,
        // and stores these into a texture. This shader will combine moments of the surrounding 
        // pixels using the same weights as for colors, and the combined moments are used on the next iteration.
        lum_mean_hf = filtered_moments.x;
        float lum_variance_hf = max(1e-8, filtered_moments.y - filtered_moments.x * filtered_moments.x);
        sigma_l_hf = min(max(hist_len_hf - (spec_iteration == 0 ? 0 : 2), 1), 16) / (2.0 * lum_variance_hf);
    } else {
    //  // If there is no history, treat all moments as invalid, because 3x3 spatial 
    //  // is just not enough to get reasonable filtering. Ignore luminance in this case,
    //  // and perform a depth-normal-guided bilateral blur.
        lum_mean_hf = filtered_moments.x;
        if(hist_len_hf > 1) sigma_l_hf = 0.005f;
    }

    // reduce the HF filter sensitivity to normals when the lighting is invalidated
 float normal_weight_scale = clamp(hist_len_hf / 8.0f, 0, 1);

    float normal_weight_hf = 12;
    const float CenterMetallic = MetallicA[ipos].x;
    const float roughness_center = MetallicA[ipos].y;
    normal_weight_hf *= normal_weight_scale;
    float normal_weight_spec = RoughnessSquareToSpecPower(square(roughness_center));
    normal_weight_spec = clamp(normal_weight_spec, 8, 1024);
    normal_weight_spec *= normal_weight_scale;




    float sum_w_hf = 1.0;
    float sum_w_spec = 1.0;

    // Add some jitter to sample positions to hide the a-trous filter aliasing patterns
    // [branch] if(spec_iteration == 4) ipos += int2((random(spec_iteration, gl_GlobalInvocationID.xy) - 0.5f) * step_size);

    float spec_filter_width_scale = clamp(roughness_center * 30 - spec_iteration, 0.1f, 1);


    // Compute the weighted average of color and moments from a sparse 3x3 pattern around the target pixel
    [loop]for (int yy = -1; yy <= 1; yy++) {
        [unroll]for (int xx = -1; xx <= 1; xx++) {

            if (xx == 0 && yy == 0)
                continue;
            int2 p = ipos + int2(xx, yy) * step_size;// + jitter;
            int actxx = xx;
            int actyy = yy;
            if(p.x <= 0 || p.x > screen_width) {
                actxx *= -1;
            }
            if(p.y <= 0 || p.y > screen_height) {
                actyy *= -1;
            }
            p = ipos + int2(actxx, actyy) * step_size;// + jitter;

            float w = float(all((p >= 0))
                && all((p < int2(screen_width, screen_height))));
            if(w == 0) continue;

            float3 normal = normalize(i_octahedral_32(TEX_PT_NORMALS_A[p].y));

            float depth = TEX_PT_VIEW_DEPTH_A[p].x;

            float dist_z = abs(depth_center - depth);// * fwidth_depth;
            w *= exp(-dist_z);
            w *= wavelet_kernel[abs(xx)][abs(yy)];

            float w_hf = w;

            float3 c_hf = img_hf[p];
            float3 c_spec = unpackRGBE(img_spec[p]);
            float2 c_mom = img_moments[p].xy;
            float l_hf = luminance(c_hf.rgb);
            float dist_l_hf = abs(lum_mean_hf - l_hf);

            w_hf *= exp(-dist_l_hf * dist_l_hf * sigma_l_hf);

            w_hf *= 1.0f - clamp(abs(MetallicA[p].x - CenterMetallic),0,1);
            float w_spec = w_hf;

            w_spec *= spec_filter_width_scale;


            float NdotN = max(0.0, dot(normal_center, normal));

            if (normal_weight_hf > 0)
            {
                w_hf *= clamp(pow(NdotN, normal_weight_hf),0,1);
            }

            if (normal_weight_spec > 0)
            {
                w_spec *= pow(NdotN, normal_weight_spec);
            }

            filtered_hf += c_hf.rgb * w_hf;
            filtered_spec += c_spec.rgb * w_spec;
            filtered_moments += c_mom * w_hf;
            sum_w_hf += w_hf;
            sum_w_spec += w_spec;
        }
    }

    filtered_hf = filtered_hf / sum_w_hf;
    filtered_spec = filtered_spec / sum_w_spec;
    filtered_moments = filtered_moments / sum_w_hf;
}

inline SH interpolate_lf(Texture2D<float4> img_lf_shY, Texture2D<float2> img_lf_CoCg, int2 ipos)
{
    // Target pixel parameters
    float depth_center = TEX_PT_VIEW_DEPTH_A[ipos].x;
    float fwidth_depth = TEX_PT_VIEW_DEPTH_A[ipos].y;
    float3 geo_normal_center = i_octahedral_32(TEX_PT_NORMALS_A[ipos].x);


    float2 pos_lowres = (float2(ipos)+0.5) / GRAD_DWN - 0.5 + (random(75, ipos) - 0.5f);
    float2 pos_ld = floor(pos_lowres);
    float2 subpix = frac(pos_lowres - pos_ld);

    SH sum_lf = init_SH();
    float sum_w = 0;

    // 4 bilinear taps
    const int2 off[4] = { { 0, 0 }, { 1, 0 }, { 0, 1 }, { 1, 1 } };
    float w[4] = {
        (1.0 - subpix.x) * (1.0 - subpix.y),
        (subpix.x) * (1.0 - subpix.y),
        (1.0 - subpix.x) * (subpix.y),
        (subpix.x) * (subpix.y)
    };
    for (int i = 0; i < 4; i++)
    {
        int2 p_lowres = int2(pos_ld)+off[i];
        int2 p_hires = p_lowres * GRAD_DWN + 1;

        // Low-res pixel parameters
        float p_depth = TEX_PT_VIEW_DEPTH_A[p_hires].x;
        float3 p_geo_normal = i_octahedral_32(TEX_PT_NORMALS_A[p_hires].x);

        // Start with bilinear weight
        float p_w = w[i];

        // Compute depth and normal similarity between the target pixel and the low-res anchor pixel
        float dist_depth = abs(p_depth - depth_center) * fwidth_depth;
        p_w *= exp(-dist_depth);
        p_w *= pow(max(0.0, dot(geo_normal_center, p_geo_normal)), 8);

        if (p_w > 0)
        {
            SH p_lf = load_SH(img_lf_shY, img_lf_CoCg, p_lowres);
            accumulate_SH(sum_lf, p_lf, p_w);
            sum_w += p_w;
        }
    }

    if (sum_w > 0)
    {
        // We found at least one relevant pixel among the 4 bilinear taps - good
        float inv_w = 1.0f / (sum_w);
        sum_lf.shY *= inv_w;
        sum_lf.CoCg *= inv_w;
    }
    else
    {
        // We didn't find anything relevant, so use the full-res temporally filtered LF data instead
        sum_lf = load_SH(TEX_ASVGF_HIST_COLOR_LF_SH_A, TEX_ASVGF_HIST_COLOR_LF_COCG_A, ipos);
    }

    return sum_lf;
}


#ifdef HDRP
    Texture2DArray<float4> DiffuseGBuffer;
    Texture2DArray<float4> SpecularGBuffer;
#else
    Texture2D<float4> DiffuseGBuffer;
    Texture2D<float4> SpecularGBuffer;
#endif

float3 composite_color(float4 surf_base_color,
    float3 projected_lf, float3 high_freq, float3 specular, float3 SpecColor, int2 ipos)
{
    float Exposure = 1;
    if(UseExposure) Exposure = ExposureBuffer[0];
    float3 final_color = ((surf_base_color.w == 1) ? pow(surf_base_color, 1.0f) : ((projected_lf.rgb + high_freq.rgb) * surf_base_color.xyz / Exposure + specular * SpecColor / Exposure));

    return final_color;
}

Texture2D<half2> TEX_ASVGF_ATROUS_PING_MOMENTS;
Texture2D<uint> TEX_ASVGF_ATROUS_PING_SPEC;
RWTexture2D<float4> IMG_ASVGF_COLOR;

[numthreads(16, 16, 1)]
void Atrous(uint3 gl_GlobalInvocationID : SV_DispatchThreadID, uint3 gl_WorkGroupID : SV_GroupID, uint gl_LocalInvocationIndex : SV_GroupIndex, uint3 gl_LocalInvocationID : SV_GroupThreadID)
{
    int2 ipos = gl_GlobalInvocationID.xy;
    if (any((ipos >= int2(screen_width, screen_height))))
        return;

    float3 filtered_hf;
    float3 filtered_spec;
    float2 filtered_moments;

    filter_image(TEX_ASVGF_ATROUS_PING_HF, TEX_ASVGF_ATROUS_PING_SPEC, TEX_ASVGF_ATROUS_PING_MOMENTS, filtered_hf, filtered_spec, filtered_moments, ipos);
    

    if(spec_iteration < 4) {
        IMG_ASVGF_ATROUS_PING_HF[ipos] = float4(filtered_hf,1);
        IMG_ASVGF_ATROUS_PING_SPEC[ipos] = packRGBE(filtered_spec);
        IMG_ASVGF_ATROUS_PING_MOMENTS[ipos] = filtered_moments;
    }

    // Perform compositing on the last iteration
    if (spec_iteration == MaxIterations)
    {
        SH filtered_lf = interpolate_lf(TEX_ASVGF_ATROUS_PING_LF_SH, TEX_ASVGF_ATROUS_PING_LF_COCG, ipos);


        float3 normal = i_octahedral_32(TEX_PT_NORMALS_A[ipos].y);
        float4 base_color = float4(unpackRGBE(AlbedoColorB[ipos].x),GetBounceData(GlobalColorsRead[ipos.x + ipos.y * screen_width].MetRoughIsSpec));// TEX_PT_BASE_COLOR_A.SampleLevel(sampler_trilinear_clamp, ipos / float2(screen_width, screen_height), 0);
        if(UpscalerMethod != 0 && DiffRes && base_color.w <= 2) base_color.xyz = 1;
        if(base_color.w == 1) base_color = float4(GlobalColorsRead[ipos.x + ipos.y * screen_width].Data,1);
        // Project the spherical harmonics lighting onto the actual surface normal
        float3 projected_lf = project_SH_irradiance(filtered_lf, normal);
        projected_lf *= 1024.0f;
        
        float3 final_color = composite_color(base_color, projected_lf, filtered_hf, filtered_spec, (UpscalerMethod != 0 && DiffRes && base_color.w <= 2) ? 1 : unpackRGBE(AlbedoColorB[ipos].y), ipos);

        IMG_ASVGF_COLOR[ipos] = float4(final_color, 0);
    
    }
} 

float NearPlane;
#pragma kernel DistanceCorrectionKernel
float FetchDepth(float2 UV) {
    Ray ray = CreateCameraRay(UV * 2.0f - 1.0f);  
    #ifdef HDRP
        float depth = 1.0f - (Depth[int3(UV * float2(screen_width, screen_height),0)].x);
    #else
        float depth = 1.0f - (Depth.SampleLevel(my_linear_clamp_sampler, UV, 0).x);
    #endif
        depth = NearPlane * FarPlane / (depth * (NearPlane - FarPlane) + FarPlane);
        return length(ray.direction / dot(ray.direction, Forward) * depth);   
}

RWTexture2D<half2> TEX_PT_VIEW_DEPTH_AWRITE;//current frame depth
[numthreads(32, 32, 1)]
void DistanceCorrectionKernel(uint3 id : SV_DispatchThreadID) {
    if(id.x > screen_width || id.y > screen_height) return;
    float2 Uv = (id.xy + 0.5f) / float2(screen_width, screen_height);

    float CurDepth = FetchDepth(Uv);
    float CurDepthX = FetchDepth(Uv + float2(rcp(screen_width) * 2.0f, 0));
    float CurDepthY = FetchDepth(Uv + float2(0, rcp(screen_height) * 2.0f));
    float CurDepthX2 = FetchDepth(Uv - float2(rcp(screen_width) * 2.0f, 0));
    float CurDepthY2 = FetchDepth(Uv - float2(0, rcp(screen_height) * 2.0f));
    TEX_PT_VIEW_DEPTH_AWRITE[id.xy] = float2(CurDepth, abs(CurDepth - CurDepthX) + abs(CurDepth - CurDepthY) + abs(CurDepth - CurDepthY2) + abs(CurDepth - CurDepthX2));
}

#pragma kernel TempCopyKernel

[numthreads(32, 32, 1)]
void TempCopyKernel(uint3 id : SV_DispatchThreadID) {
    IMG_ASVGF_ATROUS_PING_SPEC[id.xy] = asuint(TEX_ASVGF_FILTERED_SPEC_B[id.xy].x);
}